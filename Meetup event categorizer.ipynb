{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meetups data - A study case about Meetup's events and events' category predction\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENT:\n",
    "- [Introduction to the meetup problem](#Introduction-to-the-meetup-problem)\n",
    "- [Database tables and your features](#Database-tables-and-your-features)\n",
    "- [Dataset's features](#Dataset's-features)\n",
    "- [Dealing with the features](#Dealing-with-the-features)\n",
    "    - [Categorical features](#Categorical-features)\n",
    "    - [Text features](#Text-features)\n",
    "    - [Numeric features](#Numeric-features)\n",
    "- [Train and Test some models](#Train%2FTest-some-models)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [How to put the model in production?](#How-to-put-the-model-in-production%3F)\n",
    "- [Attacking other problems with this model](#Attacking-other-problems-with-this-model)\n",
    "- [Other possibles problems to attack](#Attacking-other-problems-with-this-data)\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the problem\n",
    "\n",
    "I have [here](https://www.kaggle.com/sirpunch/meetups-data-from-meetupcom#categories.csv) a Kaggle's dataset which represents some relationed tables of [Meetup's](https://www.meetup.com/) events database, exporteds in [CSV](https://pt.wikipedia.org/wiki/Comma-separated_values) files. \n",
    "With the following Entity-Relationship model:\n",
    "\n",
    "<img src=\"EER-diagram.png\">\n",
    "\n",
    "\n",
    "The problem I have to attack here is the one that follows:\n",
    "\n",
    "Given a __new created group__ with the host city, the place where there will be any meetings between the members, what topics characterize the group and the name and description of the group. What is the __category__ of the group (Arts & Culture, Career & Business, etc...)?\n",
    "\n",
    "#### __Why to do that?__\n",
    "\n",
    "Well, the answer is quite simple. Sugesting a category or automatically labeling this new group we would save time of the user at creation of this Meetup group and keep this categorical data more consistent and robust.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database tables and your features\n",
    "\n",
    "In this section I will cover the dataset and your features. As said before, our dataset consists of some related tables, and they are:\n",
    "    - events\n",
    "    - venues\n",
    "    - cities\n",
    "    - categories\n",
    "    - groups\n",
    "    - members\n",
    "    - groups_topics\n",
    "    - topics\n",
    "    - members_topics\n",
    "\n",
    "As we know, the problem I have to attack is: given a new group, categorize it. So, for this activity, some tables will be useless, since the group is new and the only data we have about are: group's city, name, description and topics. So it doesn't have relationship with tables like: _events_ and _venues_.\n",
    "\n",
    "\n",
    "I'm going to use pandas to take a look at columns of __each table__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['group_id', 'category_id', 'category.name', 'category.shortname',\n",
      "       'city_id', 'city', 'country', 'created', 'description',\n",
      "       'group_photo.base_url', 'group_photo.highres_link',\n",
      "       'group_photo.photo_id', 'group_photo.photo_link',\n",
      "       'group_photo.thumb_link', 'group_photo.type', 'join_mode', 'lat',\n",
      "       'link', 'lon', 'members', 'group_name', 'organizer.member_id',\n",
      "       'organizer.name', 'organizer.photo.base_url',\n",
      "       'organizer.photo.highres_link', 'organizer.photo.photo_id',\n",
      "       'organizer.photo.photo_link', 'organizer.photo.thumb_link',\n",
      "       'organizer.photo.type', 'rating', 'state', 'timezone', 'urlname',\n",
      "       'utc_offset', 'visibility', 'who'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading GROUPS table csv file:\n",
    "groups = pd.read_csv(\"files/groups.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "print(groups.columns)\n",
    "\n",
    "# Number of columns:\n",
    "len(groups.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there's a lot of columns in this table, but a fewer can be good features to our model. If we take a deeper look on the columns we have ids (as foreign keys) to other tables, we have URLs to images from organizers or images from the group, all this kind of things that are not related as good features to classify our group category.\n",
    "\n",
    "We also have the __category name__, our target to the model in the same table, therefore, it facilities our work and we are not going to need to use foreign keys to access our target category.\n",
    "\n",
    "I'm going to remove these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['group_id', 'category.name', 'city_id', 'city', 'country', 'created',\n",
      "       'description', 'join_mode', 'members', 'group_name', 'rating', 'state',\n",
      "       'timezone', 'visibility', 'who'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the features I'm interested in:\n",
    "groups = groups[\n",
    "    [\n",
    "        \"group_id\",\n",
    "        \"category.name\",\n",
    "        \"city_id\",\n",
    "        \"city\",\n",
    "        \"country\",\n",
    "        \"created\",\n",
    "        \"description\",\n",
    "        \"join_mode\",\n",
    "        \"members\",\n",
    "        \"group_name\",\n",
    "        \"rating\",\n",
    "        \"state\",\n",
    "        \"timezone\",\n",
    "        \"visibility\",\n",
    "        \"who\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(groups.columns)\n",
    "\n",
    "# Number of columns:\n",
    "len(groups.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, now our dataset _groups_ have only features which are useful and provided at group's creation moment. This is the kind of feature we need to train/test our model.\n",
    "\n",
    "In other moment I will check how the data is varying in some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>shortname</th>\n",
       "      <th>sort_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Arts &amp; Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Arts &amp; Culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Career &amp; Business</td>\n",
       "      <td>Business</td>\n",
       "      <td>Career &amp; Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cars &amp; Motorcycles</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Cars &amp; Motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id       category_name shortname           sort_name\n",
       "0            1      Arts & Culture      Arts      Arts & Culture\n",
       "1            2   Career & Business  Business   Career & Business\n",
       "2            3  Cars & Motorcycles      Auto  Cars & Motorcycles"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.read_csv(\"files/categories.csv\", encoding=\"utf-8\")\n",
    "categories.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, all this data in table _categories_, we already have as a _group's_ column. So, we can ignore this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groups_topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_key</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>241031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>289172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>295444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>1040320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>1403055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id   topic_key  topic_name  group_id\n",
       "0        83  sportsfans  Sports Fan    241031\n",
       "1        83  sportsfans  Sports Fan    289172\n",
       "2        83  sportsfans  Sports Fan    295444\n",
       "3        83  sportsfans  Sports Fan   1040320\n",
       "4        83  sportsfans  Sports Fan   1403055"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_topics = pd.read_csv(\"files/groups_topics.csv\", encoding=\"ISO-8859-1\")\n",
    "groups_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In _groups topics_ table we have an interesting data. We have here __topic names__ as a categorical feature and _group id_ and _topic id_ as FKs. \n",
    "\n",
    "We can do a left join on _groups_ table soon. For now, let's check _topics_ table, if exist any useful feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>description</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>Meet with others in your local area who are Sp...</td>\n",
       "      <td>471594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>Meet with Latin Music fans in your town.</td>\n",
       "      <td>759757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>Want to practice your English? Meetup with oth...</td>\n",
       "      <td>3176752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>Meet local Spanish language and culture lovers...</td>\n",
       "      <td>1618673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184</td>\n",
       "      <td>Meet and mingle with local Italian language an...</td>\n",
       "      <td>465231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id                                        description  members\n",
       "0        83  Meet with others in your local area who are Sp...   471594\n",
       "1       130           Meet with Latin Music fans in your town.   759757\n",
       "2       182  Want to practice your English? Meetup with oth...  3176752\n",
       "3       183  Meet local Spanish language and culture lovers...  1618673\n",
       "4       184  Meet and mingle with local Italian language an...   465231"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = pd.read_csv(\"files/topics.csv\", encoding=\"ISO-8859-1\")\n",
    "topics = topics[[\"topic_id\", \"description\", \"members\"]]\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see some useful feature like __description__, which is the topic's description and __members__, the quantity of members at each specific topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topic_id', 'description', 'members'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplifying the dataset:\n",
    "topics = topics[[\"topic_id\", \"description\", \"members\"]]\n",
    "topics.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>bio</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>hometown</th>\n",
       "      <th>joined</th>\n",
       "      <th>lat</th>\n",
       "      <th>link</th>\n",
       "      <th>lon</th>\n",
       "      <th>member_name</th>\n",
       "      <th>state</th>\n",
       "      <th>member_status</th>\n",
       "      <th>visited</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>not_found</td>\n",
       "      <td>New York</td>\n",
       "      <td>us</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2007-05-01 22:04:37</td>\n",
       "      <td>40.72</td>\n",
       "      <td>http://www.meetup.com/members/3</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>Matt Meeker</td>\n",
       "      <td>NY</td>\n",
       "      <td>active</td>\n",
       "      <td>2009-09-18 18:32:23</td>\n",
       "      <td>490552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>not_found</td>\n",
       "      <td>New York</td>\n",
       "      <td>us</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2011-01-23 14:13:17</td>\n",
       "      <td>40.72</td>\n",
       "      <td>http://www.meetup.com/members/3</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>Matt Meeker</td>\n",
       "      <td>NY</td>\n",
       "      <td>active</td>\n",
       "      <td>2011-03-20 01:02:11</td>\n",
       "      <td>1474611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hi, I'm Matt. I'm an entrepreneur who has star...</td>\n",
       "      <td>New York</td>\n",
       "      <td>us</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2010-12-30 18:47:34</td>\n",
       "      <td>40.72</td>\n",
       "      <td>http://www.meetup.com/members/3</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>Matt Meeker</td>\n",
       "      <td>NY</td>\n",
       "      <td>active</td>\n",
       "      <td>2011-01-18 20:37:23</td>\n",
       "      <td>1490492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_id                                                bio      city  \\\n",
       "0          3                                          not_found  New York   \n",
       "1          3                                          not_found  New York   \n",
       "2          3  Hi, I'm Matt. I'm an entrepreneur who has star...  New York   \n",
       "\n",
       "  country      hometown               joined    lat  \\\n",
       "0      us  New York, NY  2007-05-01 22:04:37  40.72   \n",
       "1      us  New York, NY  2011-01-23 14:13:17  40.72   \n",
       "2      us  New York, NY  2010-12-30 18:47:34  40.72   \n",
       "\n",
       "                              link   lon  member_name state member_status  \\\n",
       "0  http://www.meetup.com/members/3 -74.0  Matt Meeker    NY        active   \n",
       "1  http://www.meetup.com/members/3 -74.0  Matt Meeker    NY        active   \n",
       "2  http://www.meetup.com/members/3 -74.0  Matt Meeker    NY        active   \n",
       "\n",
       "               visited  group_id  \n",
       "0  2009-09-18 18:32:23    490552  \n",
       "1  2011-03-20 01:02:11   1474611  \n",
       "2  2011-01-18 20:37:23   1490492  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = pd.read_csv(\"files/members.csv\", encoding=\"ISO-8859-1\")\n",
    "members.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the first three rows of the dataset we can see that exists any missing data, related to __bio__'s member. Due to this, it's not good we use as a feature to extract values to the model. Let's see how many rows are missing bio value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = members.bio.value_counts()\n",
    "\n",
    "# Show first 5 repeated values.\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there's a lot of \"not_found\" values, especifically: 4,838,716. Cleary isn't a good ideia to put bio as a feature.\n",
    "\n",
    "I think we can pass this table too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Member_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_key</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>member_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>121483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>165644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>327482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>337743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>Sports Fan</td>\n",
       "      <td>sportsfans</td>\n",
       "      <td>358259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id   topic_key  topic_name  member_id\n",
       "0        83  Sports Fan  sportsfans     121483\n",
       "1        83  Sports Fan  sportsfans     165644\n",
       "2        83  Sports Fan  sportsfans     327482\n",
       "3        83  Sports Fan  sportsfans     337743\n",
       "4        83  Sports Fan  sportsfans     358259"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_topics = pd.read_csv(\"files/members_topics.csv\", encoding=\"ISO-8859-1\")\n",
    "members_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function of this table is reference topic's data with member through _member id_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3195245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "605790"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of topics linked to members:\n",
    "print(len(members_topics.member_id))\n",
    "\n",
    "# Total of members linked with at least one topic:\n",
    "len(members_topics.member_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think that is a good idea put this information as our feature to train the model because the only information we have about members, is the creator of the group, and we already going to link the group with one topic (which is a column of this table).\n",
    "\n",
    "Thus, we are passing this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_id</th>\n",
       "      <th>country</th>\n",
       "      <th>distance</th>\n",
       "      <th>latitude</th>\n",
       "      <th>localized_country_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>member_count</th>\n",
       "      <th>ranking</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West New York</td>\n",
       "      <td>7093</td>\n",
       "      <td>us</td>\n",
       "      <td>2524.541</td>\n",
       "      <td>40.790001</td>\n",
       "      <td>USA</td>\n",
       "      <td>-74.010002</td>\n",
       "      <td>661</td>\n",
       "      <td>32</td>\n",
       "      <td>NJ</td>\n",
       "      <td>7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>10001</td>\n",
       "      <td>us</td>\n",
       "      <td>2526.837</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>USA</td>\n",
       "      <td>-73.989998</td>\n",
       "      <td>229371</td>\n",
       "      <td>0</td>\n",
       "      <td>NY</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York Mills</td>\n",
       "      <td>13417</td>\n",
       "      <td>us</td>\n",
       "      <td>2392.162</td>\n",
       "      <td>43.099998</td>\n",
       "      <td>USA</td>\n",
       "      <td>-75.290001</td>\n",
       "      <td>22</td>\n",
       "      <td>109</td>\n",
       "      <td>NY</td>\n",
       "      <td>13417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>East Chicago</td>\n",
       "      <td>46312</td>\n",
       "      <td>us</td>\n",
       "      <td>1810.371</td>\n",
       "      <td>41.639999</td>\n",
       "      <td>USA</td>\n",
       "      <td>-87.459999</td>\n",
       "      <td>31</td>\n",
       "      <td>90</td>\n",
       "      <td>IN</td>\n",
       "      <td>46312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Mills</td>\n",
       "      <td>56567</td>\n",
       "      <td>us</td>\n",
       "      <td>1418.834</td>\n",
       "      <td>46.689999</td>\n",
       "      <td>USA</td>\n",
       "      <td>-95.349998</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>MN</td>\n",
       "      <td>56567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  city_id country  distance   latitude  \\\n",
       "0   West New York     7093      us  2524.541  40.790001   \n",
       "1        New York    10001      us  2526.837  40.750000   \n",
       "2  New York Mills    13417      us  2392.162  43.099998   \n",
       "3    East Chicago    46312      us  1810.371  41.639999   \n",
       "4  New York Mills    56567      us  1418.834  46.689999   \n",
       "\n",
       "  localized_country_name  longitude  member_count  ranking state    zip  \n",
       "0                    USA -74.010002           661       32    NJ   7093  \n",
       "1                    USA -73.989998        229371        0    NY  10001  \n",
       "2                    USA -75.290001            22      109    NY  13417  \n",
       "3                    USA -87.459999            31       90    IN  46312  \n",
       "4                    USA -95.349998             5        1    MN  56567  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = pd.read_csv(\"files/cities.csv\", encoding=\"ISO-8859-1\")\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table we can see repeated features, but exists some new features as __member_count__ from the cities and your ranking. But this ranking isn't clear for us what is the meaning of this information. Due to this, I will pass the feature ranking. But probably going to use __member_count__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities[\n",
    "    [\"city_id\", \"city\", \"member_count\"]\n",
    "]  # Need columns 'city' to do the match/join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset's features\n",
    "\n",
    "In this section I will put all together and build our dataset to the final model. Based on discussions of [this section](#Database-tables-and-your-features) our dataset will consist of:\n",
    "\n",
    "- __groups table__: the chosen features;\n",
    "- __groups_topics table__: we have topic_name and FKs to the _topics table_;\n",
    "- __topics table__: we have the topics' _description_ and the _members'_ quantity of each topic as features;\n",
    "- __cities table__: from this table I chose only get one feature, the _member count_ of each city, and left join with city in groups table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to remember the state of our dataframes of the respectively tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group_id          category.name  city_id      city country  \\\n",
      "0      6388       health/wellbeing    10001  New York      US   \n",
      "1      6510  community/environment    10001  New York      US   \n",
      "\n",
      "               created                                        description  \\\n",
      "0  2002-11-21 16:50:46  Those who practice or hold a strong interest i...   \n",
      "1  2003-05-20 14:48:54  The New York Alternative Energy Meetupis for t...   \n",
      "\n",
      "  join_mode    lat        lon  members                 group_name  rating  \\\n",
      "0      open  40.75 -73.989998     1440     Alternative Health NYC    4.39   \n",
      "1      open  40.75 -73.989998      969  Alternative Energy Meetup    4.31   \n",
      "\n",
      "  state    timezone visibility                      who  \n",
      "0    NY  US/Eastern     public      Explorers of Health  \n",
      "1    NY  US/Eastern     public  Clean Energy Supporters  \n"
     ]
    }
   ],
   "source": [
    "print(groups.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic_id   topic_key  topic_name  group_id\n",
      "0        83  sportsfans  Sports Fan    241031\n",
      "1        83  sportsfans  Sports Fan    289172\n"
     ]
    }
   ],
   "source": [
    "print(groups_topics.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic_id                                        description  members\n",
      "0        83  Meet with others in your local area who are Sp...   471594\n",
      "1       130           Meet with Latin Music fans in your town.   759757\n"
     ]
    }
   ],
   "source": [
    "print(topics.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_id           city  member_count\n",
      "0     7093  West New York           661\n",
      "1    10001       New York        229371\n"
     ]
    }
   ],
   "source": [
    "print(cities.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting all together:\n",
    "\n",
    "\n",
    "[HERE TALK ABOUT TECHNIQUES I'VE USED]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups.join(cities, on='city_id', rsuffix='_from_cities')\n",
    "groups_and_cities = pd.merge(\n",
    "    groups, cities, on=\"city_id\", how=\"left\", suffixes=(\"\", \"_from_cities\")\n",
    ")\n",
    "dataset = pd.merge(\n",
    "    groups_and_cities,\n",
    "    groups_topics,\n",
    "    on=\"group_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_from_groups_topics\"),\n",
    ")\n",
    "dataset = pd.merge(\n",
    "    dataset, topics, on=\"topic_id\", how=\"left\", suffixes=(\"\", \"_from_topics\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to drop duplicated and ID columns.\n",
    "\n",
    "\n",
    "Also I'm going to rename some columns to keep a kind of pattern. Will organize the columns to be renamed in a dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category                    object\n",
       "city                        object\n",
       "country                     object\n",
       "created                     object\n",
       "description                 object\n",
       "join_mode                   object\n",
       "members                      int64\n",
       "group_name                  object\n",
       "rating                     float64\n",
       "state                       object\n",
       "timezone                    object\n",
       "visibility                  object\n",
       "who                         object\n",
       "topic_name                  object\n",
       "description_from_topics     object\n",
       "members_from_topics        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping ID and useless columns:\n",
    "dataset = dataset.drop(\n",
    "    columns=[\n",
    "        \"group_id\",\n",
    "        \"city_id\",\n",
    "        \"topic_key\",\n",
    "        \"topic_id\",\n",
    "        \"city_from_cities\",\n",
    "        \"member_count\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Renaming columns:\n",
    "columns_to_rename = {\"category.name\": \"category\"}\n",
    "dataset = dataset.rename(columns=columns_to_rename)\n",
    "\n",
    "# Checking type from columns\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking missing data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category                   0\n",
      "city                       0\n",
      "country                    0\n",
      "created                    0\n",
      "description                0\n",
      "join_mode                  0\n",
      "members                    0\n",
      "group_name                 0\n",
      "rating                     0\n",
      "state                      0\n",
      "timezone                   0\n",
      "visibility                 0\n",
      "who                        0\n",
      "topic_name                 0\n",
      "description_from_topics    0\n",
      "members_from_topics        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "values = {\"description\": \"\", \"group_name\": \"\"}\n",
    "# Replacing description and group name for empty string:\n",
    "dataset = dataset.fillna(value=values)\n",
    "\n",
    "# Removing other rows with nan values:\n",
    "dataset = dataset.dropna(axis=\"rows\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Dealing with the features\n",
    "\n",
    "Now that we have our final dataset to train/test the model, we can see that most part has __categorical features__. Also have __text__ and __numeric__ features.\n",
    "\n",
    "I'm going to explain how to deal with each feature type:\n",
    "\n",
    "### Categorical features\n",
    "\n",
    "In this section, I want to attack a classic problem for ML: __Deal with categorical features on dataset__.\n",
    "\n",
    "Categorical data are common problems in many Data Science and Machine Learning approaches but are usually more challenging to deal with than numerical data. In particular, many machine learning algorithms require that their input is numerical and therefore categorical features must be transformed into numerical features before we can use any of these algorithms.\n",
    "\n",
    "Therefore, I will create a few datasets with encoded categorical variables. There are a lot of techniques to encode this data, but I'm going to use:\n",
    "\n",
    "- [__One-Hot Encoding__](http://contrib.scikit-learn.org/categorical-encoding/onehot.html): one column per category, with a 1 or 0 in each cell for if the row contained that column’s category\n",
    "- [__Binary Encoding__](http://contrib.scikit-learn.org/categorical-encoding/binary.html): first the categories are encoded as ordinal, then those integers are converted into binary code, then the digits from that binary string are split into separate columns. This encodes the data in fewer dimensions that one-hot, but with some distortion of the distances.\n",
    "- [__Backward Difference__](http://contrib.scikit-learn.org/categorical-encoding/backward_difference.html): the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level. This type of coding may be useful for a nominal or an ordinal variable.\n",
    "\n",
    "With these three encoding techniques, I will test all outputted datasets with some different models to evaluate what encoding technique better perfomed in our data.\n",
    "\n",
    "_Note: For this activity, used [Category Encoders](http://contrib.scikit-learn.org/categorical-encoding/index.html), a python package._\n",
    "\n",
    "### Text features\n",
    "To deal with the text features I'm going to use techniques known as [__feature extraction__](https://scikit-learn.org/stable/modules/feature_extraction.html), \n",
    "\n",
    "### Numeric features\n",
    "\n",
    "Before encode our dataset, I want to extract more value as possible from the date feature: _data_. Have two approaches which make sense for us, extracting them from datetime feature:\n",
    "- Day of the week\n",
    "- Day of the year\n",
    "\n",
    "However, we already got day of the week as a original column. Let's get the day of the year as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BackwardDifferenceEncoder(cols=['city', 'country', 'join_mode', 'state', 'timezone', 'visibility', 'who', 'topic_name'],\n",
       "             drop_invariant=False, handle_unknown='impute',\n",
       "             impute_missing=True,\n",
       "             mapping=[{'col': 'city', 'mapping':       [D.1]     [D.2]     [D.3]     [D.4]     [D.5]     [D.6]     [D.7]  \\\n",
       "1 -0.888889 -0.777778 -0.666667 -0.555556 -0.444444 -0.333333 -0.222222\n",
       "2  0.111111 -0.777778 -0.666667 -0.555556 -0.444444 -0.333333 -0.222222\n",
       "3  0.111111  0.222222 -0.666667 -0.5555...  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "\n",
       "[962 rows x 960 columns]}],\n",
       "             return_df=True, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's deal with text features:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# dataset = pd.read_pickle('final_dataset.pkl')\n",
    "\n",
    "text_extract_descp = dataset[\"description\"]\n",
    "text_extract_name = dataset[\"group_name\"]\n",
    "text_extract_tops = dataset[\"description_from_topics\"]\n",
    "\n",
    "# # Instancing the Vectorizer algorithm:\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Doing the transformations and putting in our dataset:\n",
    "dataset[\"description\"] = vectorizer.fit_transform(text_extract_descp)\n",
    "dataset[\"group_name\"] = vectorizer.fit_transform(text_extract_name)\n",
    "dataset[\"description_from_topics\"] = vectorizer.fit_transform(text_extract_tops)\n",
    "\n",
    "# Converting column 'created' to datetime type:\n",
    "dataset[\"created\"] = pd.to_datetime(dataset[\"created\"])\n",
    "\n",
    "# Creating numeric feature from datetimes:\n",
    "dataset[\"created\"] = dataset[\"created\"].dt.dayofyear\n",
    "\n",
    "\n",
    "# Now let's treat our categorical features:\n",
    "\n",
    "## Initializing our encoders:\n",
    "import category_encoders as ce\n",
    "\n",
    "cols = [\n",
    "    \"city\",\n",
    "    \"country\",\n",
    "    \"join_mode\",\n",
    "    \"state\",\n",
    "    \"timezone\",\n",
    "    \"visibility\",\n",
    "    \"who\",\n",
    "    \"topic_name\",\n",
    "]\n",
    "# one_hot_encoder = ce.OneHotEncoder(cols=cols, drop_invariant=True, use_cat_names=True)\n",
    "# binary_encoder = ce.BinaryEncoder(cols=cols, drop_invariant=True)\n",
    "backward_encoder = ce.BackwardDifferenceEncoder(cols=cols)\n",
    "\n",
    "# Separating target from features:\n",
    "X = dataset.loc[:, dataset.columns != \"category\"].copy()\n",
    "Y = dataset.loc[:, dataset.columns == \"category\"].copy()\n",
    "\n",
    "# Fiting our encoders to the columns we told:\n",
    "one_hot_encoder.fit(X)\n",
    "binary_encoder.fit(X)\n",
    "backward_encoder.fit(X)\n",
    "\n",
    "# Encoding our dataset:\n",
    "X_hot_encoded = one_hot_encoder.transform(X)\n",
    "X_binary_encoded = binary_encoder.transform(X)\n",
    "X_backward_encoded = backward_encoder.transform(X)\n",
    "\n",
    "train_datasets_list = [X_hot_encoded, X_binary_encoded, X_backward_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing dimension of categorical encoders\n",
    "\n",
    "\n",
    "Before put the hands on the models and metrics, I want to analyze __how many columns__ each encoding have created to our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_backward_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c095c0eab061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# X_binary_encoded.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_backward_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_backward_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "X_hot_encoded.shape\n",
    "X_binary_encoded.shape\n",
    "X_backward_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Train/Test some models\n",
    "__NOTE: My memory can't deal with these encoding transformations, I've tried differents approaches but always pass 8GB RAM, and my computer freeze, but in these following steps I would train some different models and look to the F1 measure score to decides our best model and take a quicky look at the CONFUSION MATRIX__\n",
    "\n",
    "I'm very sorry for this step, I could use Spark ou divide the step with different Memory Chuncks, but had no time :( ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'city', 'country', 'created', 'description', 'join_mode',\n",
       "       'lat', 'lon', 'members', 'group_name', 'rating', 'state', 'timezone',\n",
       "       'visibility', 'who', 'topic_name', 'description_from_topics',\n",
       "       'members_from_topics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the dataset with the 3 chosen encoders\n",
    "for df_encoded in train_datasets_list:\n",
    "    # Split train / test data:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_encoded, Y, test_size=0.25, random_state=42)\n",
    "    # Now train and test with different models with .fit() .predict()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also could use [auto sklearn](https://automl.github.io/auto-sklearn/master/index.html) or [automl](https://pypi.org/project/automl/) automatic ML model selection tools to choose the best model automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Due this problem I mentioned above, I can't tell the final decision and conclusion, but probably the metric I would choose to evaluate the best model would be _f1 score_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to put the model in production?\n",
    "\n",
    "We build a prediction model on the Meetup's historic data using different machine learning algorithms and classifiers, plot the results and calculate some score metrics of the model on the testing data. Now what? To put it to use in order to predict the new data, we have to deploy it over the target service or porduct. In this section I'll talk about two ways to deploy our model and put it in production.\n",
    "\n",
    "1. Build your own API;\n",
    "2. Use a paid service/platform (such as Cloud ML Engine from Google).\n",
    "\n",
    "\n",
    "### 1. Build your own API\n",
    "Building your own API service to your model several times is the best solution to many people, because you can use, for example, python's frameworks as Flask and it's easy to start a server with right configuration, it's customizable, you can process the data in the same call since it is python building the API and processing the data for the model,  and cheaper (for free, actually).\n",
    "\n",
    "However, this traditional approach requires a lot of setup and maintence time from software/ML engineers. Also scaling in multiple machines (clusters) using Flask causes many complications.\n",
    "\n",
    "\n",
    "### 2. Deploy using a service\n",
    "Using a platform that serves ML models usually is low latency and makes the ML model deployment to production easier and faster. The part of scale and maintain the model also is simple.\n",
    "\n",
    "Usually this platforms enable you to upload your python file with _load()_ and _predict()_ method to deploy your model and do the necessary processing.\n",
    "\n",
    "However, it demands some investment, they are not free. As example of this services we have [Panini AI](https://panini.ai/) and [Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/).\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacking other problems with this model\n",
    "\n",
    "Now, thinking about how would I apply this model to improve other platform interactions with users at Meetup's platform, I must remember that the input information from my model it's the basic data given at the creation of the meetup's group.\n",
    "\n",
    "Well, knowing the group's category this user is creating, to improve other platform interactions using the same developed model I think about two approaches:\n",
    "- Show Meetup's groups of the same category and next him (same city or state) to engage the participation in these groups;\n",
    "- Recommend some tips to the success of this new group based on the groups similar to this one\n",
    "    - With this __success__ metric I mean more group members, for example. \n",
    "\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacking other problems with this data\n",
    "\n",
    "Given all the database tables I metioned before, we can think about other problems which is possible to attack using other ML models considering all our data. For example:\n",
    "\n",
    "- To make the creation of new groups or events __easier and faster__ to the users we could try to use _The transformer neural network_ to write these descriptions automatically, and as showed in this [paper](https://arxiv.org/abs/1706.03762), it performs so well.\n",
    "\n",
    "- We also can suggest places (cities/states) would be more successful for this group or event\n",
    "\n",
    "- We could create a model which suggests to a new member, a list of groups and events based on your personal information and interests\n",
    "--------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
